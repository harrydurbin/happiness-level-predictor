{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Happiness Model: Finding correlated features and predicting happiness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Harrison Durbin\n",
    "### CE 263 - Scalable Spatial Analytics\n",
    "### Final Project\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble.forest import RandomForestRegressor\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import matplotlib.pyplot as plt \n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "py.sign_in('harry.durbin', 'q3rzsjbxdu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing raw datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data set from World Value Survey\n",
    "fn = 'WV6.csv' # approximately 85,000 individual survey results take in 60 \n",
    "# countries\n",
    "raw0 = np.genfromtxt(fn, delimiter=',', skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data set for country codes and coordinates\n",
    "fn2 = 'Country_List_ISO_3166_Codes_Latitude_Longitude.csv'\n",
    "\n",
    "name_i = [] # country name index\n",
    "abbr_i = []  # country abbreviation\n",
    "code_i = [] # country code\n",
    "lat_i = []  # approximate latitude of country center\n",
    "lng_i = []  # approximate longitude of country center\n",
    "\n",
    "with open(fn2) as f: \n",
    "    for line in f: # go over country data, line by line\n",
    "        x = line.split(',') # get a list of attributes, as strings\n",
    "        name_i.append(x[0]) # country name index\n",
    "        abbr_i.append(x[2]) # country abbreviation\n",
    "        code_i.append(int(x[3])) # country code\n",
    "        lat_i.append(float(x[4])) # approximate latitude of country center\n",
    "        lng_i.append(float(x[5])) # approximate longitiude of country center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lat = [] # latitudes for all points in complete raw survey file\n",
    "lng = [] # longitudes for all points in complete raw survey file\n",
    "abbr = [] # abbreviations for all points in complete raw survey file\n",
    "name = [] # country names for all points in complete raw survey file\n",
    "\n",
    "for y in range(len(raw0)):\n",
    "    for z in range(len(name_i)):\n",
    "        if int(raw0[y,1]) == int(code_i[z]):\n",
    "            lat.append(lat_i[z]) \n",
    "            lng.append(lng_i[z])\n",
    "            abbr.append(abbr_i[z])\n",
    "            name.append(name_i[z]) \n",
    "\n",
    "lat = np.asarray(lat)\n",
    "lng = np.asarray(lng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(np.unique(name)) # gives number of countries in raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.vstack((lat,lng)).T # array of country coordinates for all of the raw\n",
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating regional country clusters based on geography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initializing minibatch kmeans\n",
    "n = 10\n",
    "mbkm = MiniBatchKMeans(n_clusters=n, init='k-means++', max_iter=100, batch_size=100, \n",
    "                 verbose=0, compute_labels=True, random_state=None, tol=0.0, \n",
    "                       max_no_improvement=10, init_size=None, n_init=3, \n",
    "                       reassignment_ratio=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# running minibatch kmeans\n",
    "mbkm.fit(X) \n",
    "mbkm_labels = mbkm.labels_ # this is an array that indicates cluster\n",
    "mbkm_labels = np.asarray(mbkm_labels)\n",
    "mbkm_cluster_centers = mbkm.cluster_centers_ \n",
    "mbkm_labels_unique = np.unique(mbkm_labels)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#compiling countries into 10 cluster groups\n",
    "group_a = []\n",
    "group_b = []\n",
    "group_c = []\n",
    "group_d = []\n",
    "group_e = []\n",
    "group_f = []\n",
    "group_g = []\n",
    "group_h = []\n",
    "group_i = []\n",
    "group_j = []\n",
    "\n",
    "for x in range(len(name)):\n",
    "    for y in range(len(mbkm_labels_unique)):\n",
    "        if mbkm_labels[x] == 0:\n",
    "            group_a.append(str(name[x]))\n",
    "        if mbkm_labels[x] == 1:\n",
    "            group_b.append(str(name[x]))\n",
    "        if mbkm_labels[x] == 2:\n",
    "            group_c.append(str(name[x]))\n",
    "        if mbkm_labels[x] == 3:\n",
    "            group_d.append(str(name[x]))\n",
    "        if mbkm_labels[x] == 4:\n",
    "            group_e.append(str(name[x]))\n",
    "        if mbkm_labels[x] == 5:\n",
    "            group_f.append(str(name[x]))\n",
    "        if mbkm_labels[x] == 6:\n",
    "            group_g.append(str(name[x]))\n",
    "        if mbkm_labels[x] == 7:\n",
    "            group_h.append(str(name[x]))      \n",
    "        if mbkm_labels[x] == 8:\n",
    "            group_i.append(str(name[x]))      \n",
    "        if mbkm_labels[x] == 9:\n",
    "            group_j.append(str(name[x]))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print which countries are in each cluster\n",
    "group_a = np.unique(group_a)\n",
    "group_b = np.unique(group_b)\n",
    "group_c = np.unique(group_c)\n",
    "group_d = np.unique(group_d)\n",
    "group_e = np.unique(group_e)\n",
    "group_f = np.unique(group_f)\n",
    "group_g = np.unique(group_g)\n",
    "group_h = np.unique(group_h)\n",
    "group_i = np.unique(group_i)\n",
    "group_j = np.unique(group_j)\n",
    "\n",
    "print 'Group A is:'\n",
    "print group_a\n",
    "print 'Group B is:'\n",
    "print group_b\n",
    "print 'Group C is:'\n",
    "print group_c\n",
    "print 'Group D is:'\n",
    "print group_d\n",
    "print 'Group E is:'\n",
    "print group_e\n",
    "print 'Group F is:'\n",
    "print group_f\n",
    "print 'Group G is:'\n",
    "print group_g\n",
    "print 'Group H is:'\n",
    "print group_h\n",
    "print 'Group I is:'\n",
    "print group_i\n",
    "print 'Group J is:'\n",
    "print group_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw0.shape # gives the length of raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create array of latitude, longitude, and cluster group\n",
    "raw1 = np.vstack((lat.T,lng.T,mbkm_labels.T)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw1.shape # verifying correct dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# combines the raw data with the new lat, lng, cluster array\n",
    "raw = np.vstack((raw0.T,raw1)).T "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw.shape # verifying correct dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the data (removing rows that have any missing or inaccurate values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# delete row from array if values are missing/inaccurate in the survey\n",
    "# column numbers are referenced from features list below\n",
    "\n",
    "# V10: would you say you are 1 V. Happy, 2 Rather Happy, \n",
    "# 3 Not v. happy, 4 not at all happy\n",
    "raw = raw[~(raw[:,10]<1)]\n",
    "\n",
    "# V11: how would you describe your state of health these days? \n",
    "# 1 V. Good, 2 Good, 3 Fair, 4 Poor\n",
    "raw = raw[~(raw[:,11]<1)]\n",
    "\n",
    "# V57: Are you: 1 Married, 2 Living together,3 Divorced, \n",
    "# 4 Separated, 5 Widowed, 6 Single\n",
    "raw = raw[~(raw[:,59]<1)] \n",
    "\n",
    "# V58: Have you had any children? 0 - 8\n",
    "raw = raw[~(raw[:,60]<0)] \n",
    "\n",
    "# V143: do you think about the meaning and purpose of life? \n",
    "# 1 Often, 2 sometimes, 3 rarely, 4 never\n",
    "raw = raw[~(raw[:,163]<1)]\n",
    "\n",
    "# V146: how often do you pray? 1 sev time per day, 2 once/day \n",
    "# 3 sev times per week, 4 only services, 5 holy days, 6 1/yr, 7 less, 8 never\n",
    "raw = raw[~(raw[:,166]<1)]\n",
    "\n",
    "# V147: would you say you are: 1 religious, 2 not religious, 3 athiest\n",
    "raw = raw[~(raw[:,167]<1)] \n",
    "\n",
    "# V229: are you employed now? hours/wk? YES: 1 full time, 2 partime, 3 self, \n",
    "# NO: 4 retired, 5 housewife, 6 student, 7 unempl., 8 other\n",
    "raw = raw[~(raw[:,297]<1)]\n",
    "\n",
    "# V231: are work tasks manual or intellectual? 1=mostly manual, 10=mostly intellectual\n",
    "raw = raw[~(raw[:,299]<1)]\n",
    "\n",
    "# V232: are work tasks routine or creative? 1=mostly routine, 10=mostly creative\n",
    "raw = raw[~(raw[:,300]<1)]\n",
    "\n",
    "# V238: would you describe yourself in: 1 upper class, 2 upper mid class, \n",
    "# 3 low mid, 4 working, 5 lower\n",
    "raw = raw[~(raw[:,306]<1)] \n",
    "\n",
    "# V240: gender, 1=male, 2=female\n",
    "raw = raw[~(raw[:,308]<1)]\n",
    "\n",
    "# V242: how old are you? 00-99\n",
    "raw = raw[~(raw[:,310]<1)] \n",
    "\n",
    "# V248: highest educational level attained? \n",
    "# 1-no formal education... 9-university level w/ degree\n",
    "raw = raw[~(raw[:,318]<1)]\n",
    "\n",
    "# V253: Size of town: 1-under 2,000 ... 8-500,000 and more\n",
    "raw = raw[~(raw[:,324]<1)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw.shape # dimensions of the new raw data array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "happy1 = raw[:,10] # list of happiness level for each person\n",
    "country1 = raw[:,1] # country code for each person\n",
    "country1_unique = np.unique(country1) # gives the unique country codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "country1_unique # the unique country codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# exploring the raw data\n",
    "\n",
    "tothappiness = [] # add of the happiness levels for each country\n",
    "avghappiness = [] # average the happiness levels for each country\n",
    "countrycounts = [] # determine the number of surveys in each country\n",
    "\n",
    "ones = [] # array with happiness level 1 (very happy)\n",
    "twos = [] # array with happiness level 2 (rather happy)\n",
    "threes = [] # array with happiness level 3 (not very happy)\n",
    "fours = [] # array with happiness level 4 (not at all happy)\n",
    "\n",
    "for x in range(len(country1_unique)):\n",
    "    count = 0\n",
    "    one = 0\n",
    "    two = 0\n",
    "    three = 0\n",
    "    four = 0\n",
    "    totalhappiness = 0\n",
    "    for y in range(len(raw)):\n",
    "        if country1[y] == country1_unique[x]:\n",
    "            count += 1\n",
    "            totalhappiness += happy1[y]\n",
    "            if happy1[y] == 1:\n",
    "                one += 1\n",
    "            elif happy1[y] == 2:\n",
    "                two += 1\n",
    "            elif happy1[y] == 3:\n",
    "                three += 1\n",
    "            elif happy1[y] == 4:\n",
    "                four += 1\n",
    "                \n",
    "    ones.append(one)\n",
    "    twos.append(two)\n",
    "    threes.append(three)\n",
    "    fours.append(four)\n",
    "    \n",
    "    tothappiness.append(totalhappiness)\n",
    "    countrycounts.append(count)\n",
    "    avghappiness.append(totalhappiness/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lat2 = []\n",
    "lng2 = []\n",
    "abbr2 = []\n",
    "name2 = []\n",
    "\n",
    "for y in range(len(country1_unique)):\n",
    "    for z in range(len(name_i)):\n",
    "        if int(country1_unique[y]) == int(code_i[z]):\n",
    "            lat2.append(lat_i[z])\n",
    "            lng2.append(lng_i[z])\n",
    "            abbr2.append(abbr_i[z])\n",
    "            name2.append(name_i[z]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for row in range(len(name2)):\n",
    "    print name2[row]\n",
    "    print '  Average happiness level:', format(avghappiness[row],'.2f')\n",
    "    print '  Total surveyed:', countrycounts[row]\n",
    "    print '    Very happy percentage', ones[row]*100/countrycounts[row],'%'\n",
    "    print '    Rather happy percentage', twos[row]*100/countrycounts[row],'%'\n",
    "    print '    Not very happy percentage', threes[row]*100/countrycounts[row],'%'\n",
    "    print '    Not happy at all percentage', fours[row]*100/countrycounts[row],'%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plotting a bar chart of the number of surveys in each country\n",
    "data = [\n",
    "    go.Bar(\n",
    "        x=name2,\n",
    "        y= countrycounts\n",
    "    )\n",
    "]\n",
    "plot_url = py.plot(data, filename='eda-bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting into Train and Test data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# k-fold data dividing\n",
    "kf = cross_validation.KFold(n=len(raw), n_folds=10, indices=None, \n",
    "                       shuffle=False, random_state=None)\n",
    "for train_index, test_index in kf:\n",
    "    raw_train, raw_test = raw[train_index], raw[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting features (for training set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## This is a list of the important features to extract from raw data\n",
    "# the code V### after the feature name is the variable code number\n",
    "\n",
    "# Col 10 - Happiness (1-4), V10\n",
    "\n",
    "# Col 2 - Country Code, V2A\n",
    "# Col 59 - Marital Status, V57\n",
    "# Col 60 - No. of Children, V58\n",
    "# Col 167 - Religious, V147\n",
    "# Col 306 - Social Class, V238\n",
    "# Col 307 - Scale of Income, V239\n",
    "# Col 310 - Age, V242\n",
    "# Col 324 - Size of Town, V253\n",
    "\n",
    "# Col 11 - Health, V11\n",
    "# Col 163 - Thoughts about life meaning, V143 ###\n",
    "# Col 297 - Employment Status, V229\n",
    "# Col 299 - Manual v Intellectual Work, V231 ###\n",
    "# Col 300 - Routine v Creative Work, V232 ####\n",
    "# Col 308 - Sex, V240\n",
    "# Col 318 - Education, V248\n",
    "# col 166 - Prayer, V146"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print raw_train.shape # dimensions of train data\n",
    "print raw_test.shape # dimensions of trest data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "latitude = raw_train[:,430]\n",
    "longitude = raw_train[:,431]\n",
    "cluster = raw_train[:,432]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "happy = raw_train[:,10]\n",
    "\n",
    "country = raw_train[:,1]\n",
    "marital = raw_train[:,59]\n",
    "kids = raw_train[:,60]\n",
    "rel = raw_train[:,167]\n",
    "scl = raw_train[:,306]\n",
    "income = raw_train[:,307]\n",
    "age = raw_train[:,310]\n",
    "town = raw_train[:,324]\n",
    "\n",
    "health = raw_train[:,11]\n",
    "purpose = raw_train[:,163]\n",
    "employment = raw_train[:,297]\n",
    "intellect_work = raw_train[:,299]\n",
    "creative_work = raw_train[:,300]\n",
    "sex = raw_train[:,308]\n",
    "education = raw_train[:,318]\n",
    "pray = raw_train =  raw_train[:,166]\n",
    "\n",
    "names = ['country','marital','kids','religious','social class','income','age',\n",
    "         'town','health','think about life','employment','intellectual work',\n",
    "         'creative work','sex','education', 'pray', 'latitude', 'longitude',\n",
    "         'cluster']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting features (for test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "happy_test = raw_test[:,10]\n",
    "\n",
    "country_test = raw_test[:,2]\n",
    "marital_test = raw_test[:,59]\n",
    "kids_test = raw_test[:,60]\n",
    "rel_test = raw_test[:,167]\n",
    "scl_test = raw_test[:,306]\n",
    "income_test = raw_test[:,307]\n",
    "age_test = raw_test[:,310]\n",
    "town_test = raw_test[:,324]\n",
    "\n",
    "health_test = raw_test[:,11]\n",
    "purpose_test = raw_test[:,163]\n",
    "employment_test = raw_test[:,297]\n",
    "intellect_work_test = raw_test[:,299]\n",
    "creative_work_test = raw_test[:,300]\n",
    "sex_test = raw_test[:,308]\n",
    "education_test = raw_test[:,318]\n",
    "pray_test = raw_test[:,166]\n",
    "\n",
    "latitude_test = raw_test[:,430]\n",
    "longitude_test = raw_test[:,431]\n",
    "cluster_test = raw_test[:,432]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling into a single matrix (for training set and for test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = np.vstack((country, marital, kids, rel, scl, income, age, town, health,\n",
    "                      purpose, employment, intellect_work,creative_work,sex,education,\n",
    "                      pray, latitude, longitude, cluster))\n",
    "features = features.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_test = np.vstack((country_test, marital_test, kids_test, rel_test, \n",
    "                           scl_test, income_test,age_test, town_test, health_test,\n",
    "                           purpose_test, employment_test,intellect_work_test, \n",
    "                           creative_work_test, sex_test, education_test, pray_test, \n",
    "                           latitude_test, longitude_test, cluster_test))\n",
    "features_test = features_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print features.shape\n",
    "print features_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training (fitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(random_state=0, n_estimators=100, max_depth=10)\n",
    "dt = DecisionTreeClassifier(min_samples_split=20, random_state=99)\n",
    "nn = KNeighborsRegressor(n_neighbors=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dt = dt.fit(features,happy) # decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn = nn.fit(features,happy)  # nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rf = rf.fit(features,happy) # random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Happiness levels for test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# predictions for decision tree method\n",
    "dt_predictions = dt.predict(features_test)\n",
    "\n",
    "print \"Features sorted by their score:\"\n",
    "print sorted(zip(map(lambda x: round(x, 2), dt.feature_importances_), names), \n",
    "             reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# predictions for nearest neighbor method\n",
    "nn_predictions = nn.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# predictions for random forest method\n",
    "predictions = rf.predict(features_test)\n",
    "\n",
    "# finding feature importancea\n",
    "print \"Features sorted by their score:\" \n",
    "p = sorted(zip(map(lambda x: round(x, 2), rf.feature_importances_), names), \n",
    "             reverse=True)\n",
    "print p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# putting the feature names and importance into lists\n",
    "x1 = []\n",
    "y1 = []\n",
    "for row in range(len(p)):\n",
    "    x1.append(p[row][1])\n",
    "    y1.append(p[row][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plotting a bar chart showing feature importances\n",
    "data = [\n",
    "    go.Bar(\n",
    "        x=x1,\n",
    "        y=y1,\n",
    "    )\n",
    "]\n",
    "plot_url = py.plot(data, filename='featureimportance-bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determing RMSE for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# RMSE for nearest neighbor\n",
    "nn_cv = []\n",
    "for row in range(len(nn_predictions)):\n",
    "    nn_cv.append(((round(nn_predictions[row]) - happy[row])**2)**0.5)\n",
    "print np.mean(nn_cv)\n",
    "print 100-round(np.mean(nn_cv)*100/np.mean(happy[row])), '%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# RMSE for decision tree\n",
    "dt_cv = []\n",
    "for row in range(len(dt_predictions)):\n",
    "    dt_cv.append(((round(dt_predictions[row]) - happy[row])**2)**0.5)\n",
    "print np.mean(dt_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# RMSE for random forest\n",
    "cv = []\n",
    "for row in range(len(predictions)):\n",
    "    cv.append(((round(predictions[row])-happy[row])**2)**0.5)\n",
    "print np.mean(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# nearest neighbor method has the lowest RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Comparing individualhappiness levels in test set  predicted vs actual "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from random import randrange "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    r = randrange(0,len(nn_predictions),1)\n",
    "    print '  pred:', int(round(nn_predictions[r])), '  act:',int(happy_test[r])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running predictions for the entire data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compiling the test and train feature data\n",
    "features_total = np.vstack((features_test,features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_total.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# predictions for the entire raw data set\n",
    "happy_total_predicted = nn.predict(features_total) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tothappinessp = []\n",
    "avghappinessp = []\n",
    "countrycountsp = []\n",
    "\n",
    "onesp = []\n",
    "twosp = []\n",
    "threesp = []\n",
    "foursp = []\n",
    "\n",
    "for x in range(len(country1_unique)):\n",
    "    count = 0\n",
    "    one = 0\n",
    "    two = 0\n",
    "    three = 0\n",
    "    four = 0\n",
    "    totalhappinessp = 0\n",
    "    for y in range(len(raw)):\n",
    "        if country1[y] == country1_unique[x]:\n",
    "            count += 1\n",
    "            totalhappinessp += happy_total_predicted[y]\n",
    "            if round(happy_total_predicted[y]) == 1:\n",
    "                one += 1\n",
    "            elif round(happy_total_predicted[y]) == 2:\n",
    "                two += 1\n",
    "            elif round(happy_total_predicted[y]) == 3:\n",
    "                three += 1\n",
    "            elif round(happy_total_predicted[y]) == 4:\n",
    "                four += 1\n",
    "\n",
    "    onesp.append(one)\n",
    "    twosp.append(two)\n",
    "    threesp.append(three)\n",
    "    foursp.append(four)\n",
    "            \n",
    "    tothappinessp.append(totalhappinessp)\n",
    "    countrycountsp.append(count)\n",
    "    avghappinessp.append(totalhappinessp/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for row in range(len(name2)):\n",
    "#     print name2[row]\n",
    "#     print '  avg happiness actual', format(avghappiness[row], '.2f')\n",
    "#     print '  avg happiness predicted', format(avghappinessp[row],'.2f')\n",
    "#     print '    predicted no. very happy', onesp[row]\n",
    "#     print '    predicted no. rather happy', twosp[row]\n",
    "#     print '    predicted no. not very happy', threesp[row]\n",
    "#     print '    predicted no. not at all happy', foursp[row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculating the error between actual and predicted avg happiness levels\n",
    "cv2=[]\n",
    "for i in range(len(avghappiness)):\n",
    "    cv2.append(abs(avghappiness[i]-avghappinessp[i]))\n",
    "print np.mean(cv2) # the RMSE of average country happiness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sorts the final data with the happines countries on top\n",
    "final_list = sorted(zip(avghappiness, avghappinessp, cv2, name2, countrycounts), \n",
    "              reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for row in range(len(final_list)):\n",
    "    # list of countries (top most happy)\n",
    "    print final_list[row][3] # country name\n",
    "    # average country happiness (actual)\n",
    "    print ' avg happiness (actl):',format(final_list[row][0],'.2f')\n",
    "    # average country happiness (predicted)\n",
    "    print ' avg happiness, pred:',format(final_list[row][1],'.2f') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot bar chart of error in country predictions\n",
    "data = [\n",
    "    go.Bar(\n",
    "        x=name2,\n",
    "        y= cv2\n",
    "    )\n",
    "]\n",
    "plot_url = py.plot(data, filename='countryhappiness-bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating map figure showing happiness levels across the world (actual and predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " # --- Build Map \n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lons = lng2\n",
    "lats = lat2\n",
    "happylevels = avghappiness\n",
    "happylevelsp = avghappinessp\n",
    "\n",
    "def get_marker_color(happiness):\n",
    "    # Returns different colors depending on happiness level\n",
    "    if happiness < 1.75:\n",
    "        return ('yo')\n",
    "    elif happiness < 2.0:\n",
    "        return ('mo')\n",
    "    elif happiness < 2.5:\n",
    "        return ('ro')\n",
    "    else:\n",
    "        return ('go')\n",
    "    \n",
    "eq_map = Basemap(projection='cyl', resolution = 'c', llcrnrlon=-150, llcrnrlat=-75,\n",
    "                urcrnrlon=190, urcrnrlat=75)\n",
    "    \n",
    "eq_map.drawcoastlines()\n",
    "eq_map.drawcountries()\n",
    "eq_map.bluemarble()\n",
    "eq_map.drawmapboundary()\n",
    "eq_map.drawmeridians(np.arange(0, 360, 30))\n",
    "eq_map.drawparallels(np.arange(-90, 90, 30))\n",
    " \n",
    "min_marker_size = 14\n",
    "for lon, lat, hlp in zip(lons, lats, happylevelsp):\n",
    "    x,y = eq_map(lon, lat)\n",
    "    msize = 1 * min_marker_size\n",
    "    marker_string = get_marker_color(hlp)\n",
    "    eq_map.plot(x, y, marker_string, markersize=msize)\n",
    "    \n",
    "    \n",
    "min_marker_size = 9\n",
    "for lon, lat, hl in zip(lons, lats, happylevels):\n",
    "    x,y = eq_map(lon, lat)\n",
    "    msize = 1 * min_marker_size\n",
    "    marker_string = get_marker_color(hl)\n",
    "    eq_map.plot(x, y, marker_string, markersize=msize)  \n",
    "    \n",
    "title_string = \"Average Country Happiness\\n\"\n",
    "plt.title(title_string)\n",
    "    \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
